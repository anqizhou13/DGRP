{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a small function to find nearest value and retrieve index\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "# time windows to compute \n",
    "windows = np.array([\n",
    "    [10,58], # baseline\n",
    "    [60,62], # immediately at stimulus onset\n",
    "    #[60,65],\n",
    "    #[60,70],\n",
    "    #[60,90], # entire stimulus\n",
    "    #[92,120], # recovery\n",
    "])\n",
    "\n",
    "# these correspond to the parameters extracted from Multiworm tracker using Choreograph\n",
    "col_names = [\n",
    "    't',\n",
    "    'Number',\n",
    "    'Good number',\n",
    "    'Persistence',\n",
    "    'Speed',\n",
    "    'Angular speed',\n",
    "    'Length',\n",
    "    'Instantaneous length',\n",
    "    'Width',\n",
    "    'Instantaneous width',\n",
    "    'Aspect',\n",
    "    'Instantaneous aspect',\n",
    "    'Midline',\n",
    "    'Kink',\n",
    "    'Bias',\n",
    "    'Curve',\n",
    "    'Consistency',\n",
    "    'X',\n",
    "    'Y',\n",
    "    'X velocity',\n",
    "    'Y velocity',\n",
    "    'Orientation',\n",
    "    'Crab',\n",
    "    'Path length'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get raw .dat files from all larvae and process them into a Python-readable pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = '/Volumes/eq-NCB/t2' # mount to server to retrieve data\n",
    "\n",
    "# find all RAL lines in the t2 folder\n",
    "lst = os.listdir(input)\n",
    "# change text if focusing on other genotypes\n",
    "paths = [x for x in lst if x.startswith('RAL')]\n",
    "# experimental setting, this remains unchanged\n",
    "protocol = 'p_5_60s1x30s0s#p_5_120s10x2s8s#n#n'\n",
    "\n",
    "# where to save the processed pickle files\n",
    "output = '/Volumes/TOSHIBA/RAL_project/choreograph_data' # save to local repo\n",
    "\n",
    "# loop through each window listed from User Settings\n",
    "for window in windows:\n",
    "\n",
    "    folder_each_window = '{}/{}s_{}s'.format(output,window[0],window[1])\n",
    "    # make folder for each window if it doesn't exist\n",
    "    if not os.path.exists(folder_each_window):\n",
    "        os.makedirs(folder_each_window)\n",
    "\n",
    "    # then, for each genotype\n",
    "    for path in paths:\n",
    "\n",
    "        startTime = time.time()\n",
    "        \n",
    "        # if raw choreograph files are already analyzed, skip this genotype\n",
    "        output_file = '{}/{}.pkl'.format(folder_each_window,path)\n",
    "        if os.path.exists(output_file) == True:\n",
    "            print(\"Genotype alreay processed, skipping {}\".format(path))\n",
    "            continue\n",
    "\n",
    "        print(\" Processing {}...\".format(path))\n",
    "\n",
    "        # find all choreograph files for each larva\n",
    "        chor_files = glob.glob(\"{}/{}/{}/**/**.dat\".format(input,path,protocol), recursive = True)\n",
    "\n",
    "        # for each file\n",
    "        data = []\n",
    "\n",
    "        for chor_file in tqdm(chor_files):\n",
    "\n",
    "            temp = []\n",
    "            # open the choreograph file\n",
    "            f = open(chor_file, \"r\")\n",
    "            f = f.read()\n",
    "            # break down line\n",
    "            f = f.split(\"\\n\")\n",
    "\n",
    "            # convert each line from string to array\n",
    "            for i in range(len(f)-1):\n",
    "                if len(f[i].split()) == len(col_names):\n",
    "                    temp.append(np.array(f[i].split(),dtype = float))\n",
    "            temp = np.transpose(np.array(temp))\n",
    "            temp = temp[:,np.where((temp[0]>window[0]) & (temp[0]<window[1]))]\n",
    "            temp = np.array(np.mean(temp,axis=1))\n",
    "            data.append(temp)\n",
    "        \n",
    "        data = np.transpose(np.array(data))\n",
    "        with open(output_file,'wb') as handle:\n",
    "            pickle.dump(data,handle)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
